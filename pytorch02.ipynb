{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZAMLOfQN/zH3oroGxQnX3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therishabhmittal-05/Pytorch/blob/main/pytorch02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ulJriLsvz0YA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/pima-indians-diabetes.data.csv\")"
      ],
      "metadata": {
        "id": "keOEcuiD4MDU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.to_numpy()"
      ],
      "metadata": {
        "id": "ri9_RH3_4TWz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset[:, :8]\n",
        "y = dataset[:, 8]"
      ],
      "metadata": {
        "id": "ptwG6MQ-4VKA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "i7KUeMBG4r3w"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class PimaClassifier(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.h1 = nn.Linear(8, 24)\n",
        "#     self.act1 = nn.ReLU()\n",
        "#     self.h2 = nn.Linear(24, 16)\n",
        "#     self.act2 = nn.ReLU()\n",
        "#     self.h3 = nn.Linear(16, 8)\n",
        "#     self.act3 = nn.ReLU()\n",
        "#     self.output = nn.Linear(8, 1)\n",
        "#     self.act_op = nn.Sigmoid()\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     x = self.act1(self.h1(x))\n",
        "#     x = self.act2(self.h2(x))\n",
        "#     x = self.act3(self.h3(x))\n",
        "#     x = self.act_op(self.output(x))\n",
        "#     return x\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16,8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8,1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "MEC9XX7X4u_c"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0XF7Lw49Zz",
        "outputId": "d191057e-93be-410a-a8b1-f0569e52913a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=8, out_features=24, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=24, out_features=32, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (9): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lossfn = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "2dnrpRi56QNR"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch = 10\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for i in range(0, len(X), batch):\n",
        "    X_b = X[i:i+batch]\n",
        "    yhat = model(X_b)\n",
        "    y_b = y[i:i+batch]\n",
        "    loss = lossfn(yhat, y_b)\n",
        "    best_loss = min(best_loss, loss.item())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
        "print(best_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tt5pU-86--P",
        "outputId": "8abcf8db-07b3-4ae1-e3a2-286a5edd674d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.3586938679218292\n",
            "Epoch: 1, Loss: 0.37230604887008667\n",
            "Epoch: 2, Loss: 0.39301809668540955\n",
            "Epoch: 3, Loss: 0.3561338782310486\n",
            "Epoch: 4, Loss: 0.3560943603515625\n",
            "Epoch: 5, Loss: 0.3161243796348572\n",
            "Epoch: 6, Loss: 0.3793323338031769\n",
            "Epoch: 7, Loss: 0.3506118357181549\n",
            "Epoch: 8, Loss: 0.35163313150405884\n",
            "Epoch: 9, Loss: 0.3632761538028717\n",
            "Epoch: 10, Loss: 0.33372825384140015\n",
            "Epoch: 11, Loss: 0.3666835129261017\n",
            "Epoch: 12, Loss: 0.3547825515270233\n",
            "Epoch: 13, Loss: 0.3634604513645172\n",
            "Epoch: 14, Loss: 0.3488941788673401\n",
            "Epoch: 15, Loss: 0.31979766488075256\n",
            "Epoch: 16, Loss: 0.34864309430122375\n",
            "Epoch: 17, Loss: 0.3132706582546234\n",
            "Epoch: 18, Loss: 0.3359166085720062\n",
            "Epoch: 19, Loss: 0.3326673209667206\n",
            "Epoch: 20, Loss: 0.3252132833003998\n",
            "Epoch: 21, Loss: 0.3349504768848419\n",
            "Epoch: 22, Loss: 0.3202982246875763\n",
            "Epoch: 23, Loss: 0.3428819477558136\n",
            "Epoch: 24, Loss: 0.3208076059818268\n",
            "Epoch: 25, Loss: 0.3158424496650696\n",
            "Epoch: 26, Loss: 0.3200969696044922\n",
            "Epoch: 27, Loss: 0.34323781728744507\n",
            "Epoch: 28, Loss: 0.33122748136520386\n",
            "Epoch: 29, Loss: 0.31012433767318726\n",
            "Epoch: 30, Loss: 0.3177846074104309\n",
            "Epoch: 31, Loss: 0.3136414885520935\n",
            "Epoch: 32, Loss: 0.30387550592422485\n",
            "Epoch: 33, Loss: 0.31484293937683105\n",
            "Epoch: 34, Loss: 0.31635522842407227\n",
            "Epoch: 35, Loss: 0.32282406091690063\n",
            "Epoch: 36, Loss: 0.3138286769390106\n",
            "Epoch: 37, Loss: 0.30407169461250305\n",
            "Epoch: 38, Loss: 0.32902997732162476\n",
            "Epoch: 39, Loss: 0.3348405659198761\n",
            "Epoch: 40, Loss: 0.3331450819969177\n",
            "Epoch: 41, Loss: 0.34710630774497986\n",
            "Epoch: 42, Loss: 0.3432696461677551\n",
            "Epoch: 43, Loss: 0.3325527310371399\n",
            "Epoch: 44, Loss: 0.3586582839488983\n",
            "Epoch: 45, Loss: 0.3407503664493561\n",
            "Epoch: 46, Loss: 0.36991018056869507\n",
            "Epoch: 47, Loss: 0.3126200735569\n",
            "Epoch: 48, Loss: 0.32327526807785034\n",
            "Epoch: 49, Loss: 0.3124394714832306\n",
            "Epoch: 50, Loss: 0.33243829011917114\n",
            "Epoch: 51, Loss: 0.33424511551856995\n",
            "Epoch: 52, Loss: 0.32709378004074097\n",
            "Epoch: 53, Loss: 0.3176169991493225\n",
            "Epoch: 54, Loss: 0.3521445095539093\n",
            "Epoch: 55, Loss: 0.3394724726676941\n",
            "Epoch: 56, Loss: 0.3419923186302185\n",
            "Epoch: 57, Loss: 0.3087351620197296\n",
            "Epoch: 58, Loss: 0.3359125256538391\n",
            "Epoch: 59, Loss: 0.3415714204311371\n",
            "Epoch: 60, Loss: 0.34855714440345764\n",
            "Epoch: 61, Loss: 0.33730870485305786\n",
            "Epoch: 62, Loss: 0.3507958948612213\n",
            "Epoch: 63, Loss: 0.32118892669677734\n",
            "Epoch: 64, Loss: 0.3238801062107086\n",
            "Epoch: 65, Loss: 0.33043670654296875\n",
            "Epoch: 66, Loss: 0.3187384307384491\n",
            "Epoch: 67, Loss: 0.3195858895778656\n",
            "Epoch: 68, Loss: 0.3267057538032532\n",
            "Epoch: 69, Loss: 0.3225439488887787\n",
            "Epoch: 70, Loss: 0.32748931646347046\n",
            "Epoch: 71, Loss: 0.35395270586013794\n",
            "Epoch: 72, Loss: 0.34035295248031616\n",
            "Epoch: 73, Loss: 0.32618746161460876\n",
            "Epoch: 74, Loss: 0.3235909640789032\n",
            "Epoch: 75, Loss: 0.3201723098754883\n",
            "Epoch: 76, Loss: 0.31688493490219116\n",
            "Epoch: 77, Loss: 0.3183723986148834\n",
            "Epoch: 78, Loss: 0.32700735330581665\n",
            "Epoch: 79, Loss: 0.31534963846206665\n",
            "Epoch: 80, Loss: 0.31401970982551575\n",
            "Epoch: 81, Loss: 0.3090956211090088\n",
            "Epoch: 82, Loss: 0.31286248564720154\n",
            "Epoch: 83, Loss: 0.33046025037765503\n",
            "Epoch: 84, Loss: 0.3273427188396454\n",
            "Epoch: 85, Loss: 0.33943095803260803\n",
            "Epoch: 86, Loss: 0.32471346855163574\n",
            "Epoch: 87, Loss: 0.35015416145324707\n",
            "Epoch: 88, Loss: 0.32527992129325867\n",
            "Epoch: 89, Loss: 0.3496130108833313\n",
            "Epoch: 90, Loss: 0.32725149393081665\n",
            "Epoch: 91, Loss: 0.3305427134037018\n",
            "Epoch: 92, Loss: 0.321639746427536\n",
            "Epoch: 93, Loss: 0.3322884142398834\n",
            "Epoch: 94, Loss: 0.3258094787597656\n",
            "Epoch: 95, Loss: 0.3468390107154846\n",
            "Epoch: 96, Loss: 0.32143068313598633\n",
            "Epoch: 97, Loss: 0.3465670645236969\n",
            "Epoch: 98, Loss: 0.3257830739021301\n",
            "Epoch: 99, Loss: 0.3328048288822174\n",
            "0.11549363285303116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model(X)\n",
        "accuracy = (y_pred.round() == y).float().mean()\n",
        "\n",
        "print(f\"accuracy: {accuracy*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJBN07j78gZO",
        "outputId": "d340cf76-57dc-4da0-e62f-ae7e870776ac"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 77.83572387695312%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGwaDFug-IkR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}